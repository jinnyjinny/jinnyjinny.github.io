---
layout: post
title: 200303 TIL
category: TIL (Today I Learned)
permalink: /til/:day/:month/:year/:title/

tags: [TIL, detection]
comments: true
---

# Today, what I did
- CAM 논문 읽기
    - 논문의 의의
    1. image의 위치 정보를 그대로 사용하여 분류하게 한다.
    2. 이미지가 분류될 때, 어떤 부분이 이미지 분류에 영향을 미친 건지 알 수 있다. (개인적으로, back propagation의 느낌이 든다..! back propagation은  추출하고 싶은 값(target)과 실제 모델이 계산한 결과값(output)이 얼마나 차이가 나는지 구한 후에 그 오차값을 다시 뒤로 전파해가면서 각 노드가 가지고 있는 변수들을 갱신하는 알고리즘이다.) 

    - CNN에 대한 이해
    1. Conv layer의 역할: layer가 얕다면, input image에서 edge를 추출하고 layer가 깊다면, image의 feature들을 추출한다.
    2. FC layer: 그 중 softmax는 classification을 수행한다.

    - CAM의 baseline
    1. 마지막 Convolution layer를 거치고 feature map을 얻는다. 
    2. 이렇게 얻은 feature map에서 GAP를 수행한다.
    3. GAP을 거쳐 계산된 1*1의 채널들을 다 더해서 softmax에 넣어 확률값을 얻어낸다 => heat-map 완성.

    - GAP에 대한 이해
    1. CAM을 구현하기 위해 GAP을 사용한다.
    2. 장점1: 위치정보를 포함한 분류
        - CAM 이전의 분류 방법: 마지막 출력값을 낼 때 FCN(Fully Connected Network)에서 flatten으로 1차원 벡터로 만든 후에 softmax에 넣어 분류한다.
        - CAM의 분류 방법: CNN의 마지막에 Conv layer를 1*1의 채널로 나오게끔 한다. 이로서 flatten이 필요없게 된다. 
        - 계수가 없어서 overfitting에 더 안전하다(아직 무슨 말인지 이해 못함). 또한 1*1로 만들지라도, 데이터의 위치 정보가 훼손되지 않는다. 즉, GAP을 사용한다면 위치정보를 그대로 사용하여 분류할 수 있게 된다.  
    



# Today, what I realized
- 논문을 읽을 수 있어서 뿌듯했다.
- 스스로 공부할 수 있는 지식이 쌓인 것 같다는 느낌이 들었다. 
- 컨디션이 좋아서 그런지 배가 고프다. (원래는 끼니를 엄청 거름)


# Tommorow's work
- GAP 수식 증명하기 관련 알고리즘 공부하기
- GMP가 무엇인지 GAP와 뭐가 다른지 찾아보기..!
- TLI 업로드 하기
- 블로그에 논문 정리하고, ppt만들기 (내일 당장 노노)


